---
title: "Processing Urban Estates Returns"
author: "Dave Lovell"
date: "14/04/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r libraries, message = FALSE, warning = FALSE}
library("here")
library("readr")
library("dplyr")
library("digest")
library("magrittr")
library("stringr")
library("carutools") #devtools::install_github("davelovellCARU/carutools")
```
## Intro

For the time being, we're just creating a csv that makes sense and is nice to look at - so no factors or anything.

## Look see what we have here

### Read in that Data!

```{r readData, message = FALSE}
responses <- readr::read_csv(here::here("data/urbanContextData.csv"))
spec(responses)
```

## Create Unique IDs

Use hashed phone numbers, emails and postcodes. But first check that they are unique.

```{r checkphoneNumsUnique}
responses %$%
  paste0(pers_phone,pers_email,pers_postcode) %>% 
  digest::sha1() %>% 
  str_sub(1,8) -> digested

if(!(length(digested) == length(unique(digested))))
  error("Unique IDs are not unique!") else responses$uniqueId = digested

#Bring uniqueId to the front
responses %<>% relocate(uniqueId)
```

### Squish all strings

(Remove double and trailing whitespace from character columns)

```{r stringSquish}
responses %<>%
  mutate(across(is.character,str_squish))
```

### Capitalise names

```{r namecapitalisation}
responses %<>% mutate(pers_name = str_to_title(pers_name))
```

### Check emails

Do they have an '@' sign ect.?

```{r checkEmails, collapse = TRUE}
  # Do any email addresses contain whitespace?
  any(str_detect(responses$pers_email, "[:space:]"), na.rm = TRUE)
  # Do all emails look a least vaguely like an email?
  all(str_detect(responses$pers_email, ".+@.+\\..+"), na.rm = TRUE)
```

### Check Phone Numbers

And remove all whitespace

```{r checkPhones, collapse = TRUE}
responses %<>% mutate(pers_phone = str_remove_all(pers_phone, "[:space:]"))

all(str_detect(responses$pers_phone,"\\D", negate = TRUE), na.rm = TRUE)

all(nchar(responses$pers_phone) == 11, na.rm = TRUE)

#Not all phone numbers are eleven digits long.

responses %>% 
  select(uniqueId, pers_phone) %>% 
  filter(nchar(pers_phone) != 11)  %>% 
  mutate(pers_phone = paste0(str_sub(pers_phone,1,4), "[REDACTED]"))

## That 10 digit phone number matches the one on the paper form - it's a respondent mistake
```

### Check Personal Postcodes

```{r checkPostcodes, collapse = TRUE}
sum(str_detect(responses$pers_postcode, carutools::ct_postcode_regex(), negate = TRUE), na.rm = TRUE)

# There were 5 of these the first time the above line ran! All confusions between i's, 1's, 0's and O's, now corrected in the csv. As for the above:

responses %<>% mutate(pers_postcode = str_remove(pers_postcode, "[:space:]*London$"))
```

### Check ages
```{r ageCheck, collapse = TRUE}
all(responses$pers_age > 10, na.rm = TRUE)
all(responses$pers_age < 114, na.rm = TRUE)
```

### Tidy Up Gender Data

```{r tidyGender, collapse = TRUE}
responses %<>% mutate(pers_gender = str_to_lower(pers_gender))

unique(responses$pers_gender)

responses %<>% mutate(pers_gender = 
                        pers_gender %>% 
                        {replace(.,.=="m", "male")} %>% 
                        {replace(.,.=="f", "female")})

unique(responses$pers_gender)
```

### Polish Estate Names

```{r estatePolishing}
responses %<>% mutate(con_estate = str_to_title(con_estate))
```

### Check Leadership Ratings

They all need to be between 1 and 10

```{r checkLeadNumbers, collapse = TRUE}
responses %>% 
  summarise(across(starts_with("lead_"), ~all(.<=10 & .>=1, na.rm = TRUE))) %>% 
  glimpse
```
